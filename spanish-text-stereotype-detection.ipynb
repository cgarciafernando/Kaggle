{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11239111,"sourceType":"datasetVersion","datasetId":7021622}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets transformers\n!pip install --upgrade datasets\n!pip install scikit-learn\n!pip install imbalanced-learn\n!pip install accelerate>=0.26.0\n!pip install seaborn\n!pip install matplotlib\n!pip install tqdm\n!pip install sentencepiece\n!pip install sacremoses\n!pip install nltk","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Library Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_recall_fscore_support,\n    precision_score,\n    recall_score,\n    f1_score,\n    confusion_matrix,\n    classification_report,\n    roc_curve,\n    auc\n)\nfrom transformers import (\n    AutoTokenizer,\n    BertTokenizer,\n    BertForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    AdamW,\n    EarlyStoppingCallback,\n    BertConfig,\n    M2M100Tokenizer,\n    M2M100ForConditionalGeneration,\n    DataCollatorWithPadding,\n    get_scheduler\n)\nfrom imblearn.over_sampling import SMOTE\nfrom datasets import Dataset, concatenate_datasets\nfrom torch.utils.data import DataLoader\nfrom torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport sentencepiece\nimport os","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Reading train.csv and Division by Source","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/i2c-challenge-dataset/train.csv')\nprint(df['source'].unique())\n\ndetests = df[df['source'] == 'detests']\nstereohoax = df[df['source'] == 'stereohoax']\n\nprint(detests['stereotype'].value_counts())\nprint(stereohoax['stereotype'].value_counts())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Text Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n    # Eliminar enlaces web\n    text = re.sub(r'http\\S+|www\\S+', '', text)\n    # Eliminar menciones de usuarios\n    text = re.sub(r'@\\w+', '', text)\n    # Eliminar hashtags\n    text = re.sub(r'#\\w+', '', text)\n    # Eliminar palabras clave específicas (URL, user, etc.)\n    text = re.sub(r'\\b(URL|user|url|USER)\\b', '', text, flags=re.IGNORECASE)\n    # Sustituir múltiples signos de exclamación por uno solo\n    text = re.sub(r'!+', '!', text)\n    # Eliminar caracteres no deseados (manteniendo letras, números y espacios)\n    text = re.sub(r'[^\\w\\sáéíóúÁÉÍÓÚñÑ0-9]', '', text)\n    # Eliminar el símbolo @ y comillas dobles\n    text = text.replace('@', '').replace('\"', '')\n    # Eliminar espacios adicionales\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\n# Aplicar el preprocesado a los datasets\ndetests = detests.copy()\nstereohoax = stereohoax.copy()\n\ndetests['text'] = detests['text'].apply(preprocess_text)\nstereohoax['text'] = stereohoax['text'].apply(preprocess_text)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Splitting Datasets into Training, Validation, and Test Subsets","metadata":{}},{"cell_type":"code","source":"detests = detests.rename(columns={'stereotype': 'labels'})\nstereohoax = stereohoax.rename(columns={'stereotype': 'labels'})\n\ndetests_dataset = Dataset.from_pandas(detests)\nstereohoax_dataset = Dataset.from_pandas(stereohoax)\n\ntrain_test_split_detests = detests_dataset.train_test_split(test_size=0.2, seed=42)\ntrain_data_detests = train_test_split_detests['train']\ntest_data_detests = train_test_split_detests['test']\n\ntrain_valid_split_detests = train_data_detests.train_test_split(test_size=0.3, seed=42)\ntrain_data_detests = train_valid_split_detests['train']\nvalid_data_detests = train_valid_split_detests['test']\n\ntrain_test_split_stereohoax = stereohoax_dataset.train_test_split(test_size=0.2, seed=42)\ntrain_data_stereohoax = train_test_split_stereohoax['train']\ntest_data_stereohoax = train_test_split_stereohoax['test']\n\ntrain_valid_split_stereohoax = train_data_stereohoax.train_test_split(test_size=0.3, seed=42)\ntrain_data_stereohoax = train_valid_split_stereohoax['train']\nvalid_data_stereohoax = train_valid_split_stereohoax['test']\n\nprint(f\"Detests: train={len(train_data_detests)}, validation={len(valid_data_detests)}, test={len(test_data_detests)}\")\nprint(f\"Stereohoax: train={len(train_data_stereohoax)}, validation={len(valid_data_stereohoax)}, test={len(test_data_stereohoax)}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Applying Back Translation to Balance Classes","metadata":{}},{"cell_type":"code","source":"model_name = \"facebook/m2m100_418M\"\ntokenizer = M2M100Tokenizer.from_pretrained(model_name)\nmodel = M2M100ForConditionalGeneration.from_pretrained(model_name)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Usando dispositivo: {device}\")\n\nmodel.to(device)\n\ndef back_translate_es_de_es(text, src_lang, mid_lang, num_beams, temperature, top_k):\n    # Traducción de español a alemán\n    tokenizer.src_lang = src_lang\n    encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n    translated_tokens = model.generate(\n        **encoded,\n        forced_bos_token_id=tokenizer.lang_code_to_id[mid_lang],\n        do_sample=True,\n        temperature=temperature,\n        top_k=top_k,\n        num_beams=num_beams\n    )\n    mid_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n\n    # Traducción de alemán de vuelta a español\n    tokenizer.src_lang = mid_lang\n    encoded = tokenizer(mid_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n    back_translated_tokens = model.generate(\n        **encoded,\n        forced_bos_token_id=tokenizer.lang_code_to_id[src_lang],\n        do_sample=True,\n        temperature=temperature,\n        top_k=top_k,\n        num_beams=num_beams\n    )\n    back_translated_text = tokenizer.decode(back_translated_tokens[0], skip_special_tokens=True)\n    return back_translated_text\n\ndef apply_back_translation(dataset, src_lang, mid_langs, num_beams, temperature, top_k, balance_ratio, max_iterations=3):\n    df = dataset.to_pandas()\n    class_counts = df[\"labels\"].value_counts()\n    minority_class = class_counts.idxmin()\n    majority_class = class_counts.idxmax()\n    minority_df = df[df[\"labels\"] == minority_class]\n    minority_count = len(minority_df)\n    majority_count = len(df[df[\"labels\"] == majority_class])\n    target_size = int(minority_count + (majority_count - minority_count) * balance_ratio)\n    \n    print(f\"Aumentando la clase minoritaria de {minority_count} a {target_size} instancias\")\n    \n    new_translated_texts = []\n    new_labels = []\n    needed_instances = target_size - minority_count\n    instances_to_generate = minority_df[\"text\"].tolist()\n    \n    # Límite de seguridad para evitar bucles infinitos\n    iteration_count = 0\n    \n    with tqdm(total=needed_instances, desc=\"Progreso de la traducción\", unit=\"instancia\") as pbar:\n        while len(new_translated_texts) < needed_instances and iteration_count < max_iterations:\n            iteration_count += 1\n            print(f\"Iteración {iteration_count} de {max_iterations}\")\n            \n            torch.cuda.empty_cache()  # Liberar memoria GPU\n            \n            for i, text in enumerate(instances_to_generate):\n                if len(new_translated_texts) >= needed_instances:\n                    break\n                    \n                # Rotar entre idiomas intermedios\n                mid_lang = mid_langs[i % len(mid_langs)]\n                \n                try:\n                    # Realizar la traducción inversa con tiempo de espera limitado\n                    back_translated_text = back_translate_es_de_es(\n                        text, src_lang, mid_lang, num_beams, temperature, top_k\n                    )\n                    \n                    new_translated_texts.append(back_translated_text)\n                    new_labels.append(minority_class)\n                    pbar.update(1)\n                    \n                except Exception as e:\n                    print(f\"Error en la traducción: {e}\")\n                    continue\n            \n            # Si no se añadieron nuevas instancias en esta iteración, salir del bucle\n            if iteration_count == max_iterations:\n                print(\"Se alcanzó el número máximo de iteraciones\")\n                break\n                \n            torch.cuda.empty_cache()  # Liberar memoria GPU nuevamente\n    \n    # Si no se generaron suficientes instancias, informar\n    if len(new_translated_texts) < needed_instances:\n        print(f\"Advertencia: Solo se generaron {len(new_translated_texts)} de {needed_instances} instancias necesarias\")\n    \n    # Concatenar los datos originales con los generados\n    augmented_df = pd.DataFrame({\n        \"text\": new_translated_texts,\n        \"labels\": new_labels\n    })\n    \n    df = pd.concat([df, augmented_df], ignore_index=True)\n    \n    # Realizar un shuffle del dataset combinado\n    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    return Dataset.from_pandas(df)\n\n\nsrc_lang = \"es\"\nmid_langs = [\"de\", \"fr\", \"pl\"]  # Lista de idiomas intermedios\nnum_beams = 5\ntemperature = 0.8\ntop_k = 50\nbalance_ratio = 1\n\ntrain_detests_resampled = apply_back_translation(\n    train_data_detests, src_lang, mid_langs, num_beams, temperature, top_k, balance_ratio\n)\n\ntrain_stereohoax_resampled = apply_back_translation(\n    train_data_stereohoax, src_lang, mid_langs, num_beams, temperature, top_k, balance_ratio\n)\n\nvalid_data_detests_resampled = apply_back_translation(\n    valid_data_detests, src_lang, mid_langs, num_beams, temperature, top_k, balance_ratio\n)\n\nvalid_data_stereohoax_resampled = apply_back_translation(\n    valid_data_stereohoax, src_lang, mid_langs, num_beams, temperature, top_k, balance_ratio\n)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport nltk\nfrom nltk.corpus import wordnet\nfrom tqdm import tqdm\nimport pandas as pd\nfrom datasets import Dataset\n\n# Descargar WordNet y WordNet en español\nnltk.download('wordnet')\nnltk.download('omw-1.4')  # Open Multilingual WordNet (incluye español)\n\ndef get_synonyms(word):\n    \"\"\"Obtiene una lista de sinónimos para una palabra usando WordNet.\"\"\"\n    synonyms = set()\n    for syn in wordnet.synsets(word, lang=\"spa\"):\n        for lemma in syn.lemmas(lang=\"spa\"):\n            synonyms.add(lemma.name())\n    return list(synonyms)\n\ndef replace_with_synonyms(text, synonym_prob=0.3):\n    \"\"\"Reemplaza palabras en un texto por sus sinónimos con una probabilidad dada.\"\"\"\n    words = text.split()\n    new_words = []\n    for word in words:\n        if random.random() < synonym_prob:\n            synonyms = get_synonyms(word)\n            if synonyms:\n                new_words.append(random.choice(synonyms))\n            else:\n                new_words.append(word)\n        else:\n            new_words.append(word)\n    return \" \".join(new_words)\n\ndef generate_synthetic_data(dataset, balance_ratio, synonym_prob=0.3):\n    \"\"\"Genera nuevas instancias para balancear las clases utilizando sinónimos.\"\"\"\n    df = dataset.to_pandas()\n    class_counts = df[\"labels\"].value_counts()\n    minority_class = class_counts.idxmin()\n    majority_class = class_counts.idxmax()\n    minority_df = df[df[\"labels\"] == minority_class]\n    minority_count = len(minority_df)\n    majority_count = len(df[df[\"labels\"] == majority_class])\n    target_size = int(minority_count + (majority_count - minority_count) * balance_ratio)\n    print(f\"Aumentando la clase minoritaria de {minority_count} a {target_size} instancias\")\n\n    new_texts = []\n    new_labels = []\n    needed_instances = target_size - minority_count\n    instances_to_generate = minority_df[\"text\"].tolist()\n\n    with tqdm(total=needed_instances, desc=\"Generando instancias\", unit=\"instancia\") as pbar:\n        while len(new_texts) < needed_instances:\n            for text in instances_to_generate:\n                synthetic_text = replace_with_synonyms(text, synonym_prob=synonym_prob)\n                if len(new_texts) < needed_instances:\n                    new_texts.append(synthetic_text)\n                    new_labels.append(minority_class)\n                    pbar.update(1)\n                if len(new_texts) >= needed_instances:\n                    break\n\n    # Concatenar los datos originales con los generados\n    df = pd.concat([df, pd.DataFrame({\n        \"text\": new_texts,\n        \"labels\": new_labels\n    })], ignore_index=True)\n\n    # Realizar un shuffle del dataset combinado\n    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n\n    return Dataset.from_pandas(df)\n\n# Configuración\nsynonym_prob = 0.8  # Probabilidad de sustituir palabras por sinónimos\nbalance_ratio = 1\n\n# Generar datasets balanceados\ntrain_detests_resampled = generate_synthetic_data(train_data_detests, balance_ratio, synonym_prob)\ntrain_stereohoax_resampled = generate_synthetic_data(train_data_stereohoax, balance_ratio, synonym_prob)\nvalid_data_detests_resampled = generate_synthetic_data(valid_data_detests, balance_ratio, synonym_prob)\nvalid_data_stereohoax_resampled = generate_synthetic_data(valid_data_stereohoax, balance_ratio, synonym_prob)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Saving Balanced Datasets","metadata":{}},{"cell_type":"code","source":"train_detests_resampled.to_csv(\"train_detests_resampledBERTO.csv\", index=False)\ntrain_stereohoax_resampled.to_csv(\"train_stereohoax_resampledBERTO.csv\", index=False)\n\nvalid_data_detests_resampled.to_csv(\"valid_data_detests_resampledBERTO.csv\", index=False)\nvalid_data_stereohoax_resampled.to_csv(\"valid_data_stereohoax_resampledBERTO.csv\", index=False)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Loading Balanced Datasets","metadata":{}},{"cell_type":"code","source":"train_detests_resampled = pd.read_csv(\"train_detests_resampledBERTO.csv\")\ntrain_stereohoax_resampled = pd.read_csv(\"train_stereohoax_resampledBERTO.csv\")\n\nvalid_data_detests_resampled = pd.read_csv(\"valid_data_detests_resampledBERTO.csv\")\nvalid_data_stereohoax_resampled = pd.read_csv(\"valid_data_stereohoax_resampledBERTO.csv\")\n\ntrain_detests_resampled = Dataset.from_pandas(train_detests_resampled)\ntrain_stereohoax_resampled = Dataset.from_pandas(train_stereohoax_resampled)\n\nvalid_data_detests_resampled = Dataset.from_pandas(valid_data_detests_resampled)\nvalid_data_stereohoax_resampled = Dataset.from_pandas(valid_data_stereohoax_resampled)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 9. Tokenization of Balanced Subsets","metadata":{}},{"cell_type":"code","source":"bert_tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n\ntokenized_train_detests_resampled = train_detests_resampled.map(\n    lambda x: bert_tokenizer(x['text'], padding=True, truncation=True, max_length=256),\n    batched=True\n)\ntokenized_train_stereohoax_resampled = train_stereohoax_resampled.map(\n    lambda x: bert_tokenizer(x['text'], padding=True, truncation=True, max_length=256),\n    batched=True\n)\n\ntokenized_train_detests_resampled = tokenized_train_detests_resampled.with_format(\n    \"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n)\ntokenized_train_stereohoax_resampled = tokenized_train_stereohoax_resampled.with_format(\n    \"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n)\n\ntokenized_valid_data_detests_resampled = valid_data_detests_resampled.map(\n    lambda x: bert_tokenizer(x['text'], padding=True, truncation=True, max_length=256),\n    batched=True\n)\n\ntokenized_valid_data_stereohoax_resampled = valid_data_stereohoax_resampled.map(\n    lambda x: bert_tokenizer(x['text'], padding=True, truncation=True, max_length=256),\n    batched=True\n)\n\ntokenized_valid_data_detests_resampled = tokenized_valid_data_detests_resampled.with_format(\n    \"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n)\ntokenized_valid_data_stereohoax_resampled = tokenized_valid_data_stereohoax_resampled.with_format(\n    \"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 10. Checking Class Distribution","metadata":{}},{"cell_type":"code","source":"def check_class_distribution(dataset):\n\n    df = dataset.to_pandas();\n\n    class_counts = df['labels'].value_counts()\n\n    print(\"\\nDistribución de clases después de la generación:\")\n    for class_id, count in class_counts.items():\n        print(f\"Clase {class_id}: {count} instancias\")\n\n    majority_count = class_counts.max()\n    minority_count = class_counts.min()\n    proportion = majority_count / minority_count if minority_count > 0 else float('inf')\n\n    print(f\"\\nProporción entre clases: {proportion:.2f} (Mayoritaria vs Minoritaria)\")\n\ncheck_class_distribution(train_detests_resampled)\ncheck_class_distribution(train_stereohoax_resampled)\n\ncheck_class_distribution(valid_data_detests_resampled)\ncheck_class_distribution(valid_data_stereohoax_resampled)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 11. Definition of Compute Metrics Function (Added Class Weighting)","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_name = 'dccuchile/bert-base-spanish-wwm-cased'\nmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n\nloss_fn = BCEWithLogitsLoss()\n\ndef compute_metrics(p):\n    predictions = p.predictions\n    labels = p.label_ids\n\n    if not isinstance(predictions, torch.Tensor):\n        predictions = torch.tensor(predictions)\n\n    preds = predictions.argmax(dim=-1)\n\n    if torch.cuda.is_available():\n        predictions = predictions.to(device)\n        preds = preds.to(device)\n        labels = torch.tensor(labels).to(device)\n\n    labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=2).float()\n\n    loss = loss_fn(predictions, labels_one_hot)\n\n    # Calculate metrics with zero_division handling\n    precision = precision_score(labels.cpu().numpy(), preds.cpu().numpy(), average=\"weighted\", zero_division=0)\n    recall = recall_score(labels.cpu().numpy(), preds.cpu().numpy(), average=\"weighted\", zero_division=0)\n    f1 = f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average=\"weighted\", zero_division=0)\n\n    return {\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n        \"loss\": loss.item()\n    }","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 12. Training and Evaluation on Both Datasets","metadata":{}},{"cell_type":"markdown","source":"## 12.1 Training and Evaluation","metadata":{}},{"cell_type":"code","source":"# Configuración del dispositivo\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nprint(f\"Usando {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n\n# Data collator\ndata_collator = DataCollatorWithPadding(tokenizer, padding=True)\n\n# Optimizer (con weight decay explícito)\noptimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=1e-5,  # Tasa de aprendizaje\n    weight_decay=0.1  # Regularización explícita\n)\n\n# Configuración para el modelo de detests\ntraining_args_detests = TrainingArguments(\n    output_dir='./results_detests',\n    num_train_epochs=3,  # 8 épocas\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    eval_strategy=\"epoch\",\n    logging_dir='./logs_detests',\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    save_strategy='epoch',\n    weight_decay=0.24766057445487644,  # También definido en los TrainingArguments\n    learning_rate=1.6082616103256584e-05,\n    logging_steps=10,\n    save_total_limit=3,\n    lr_scheduler_type='linear',\n    warmup_ratio=0.1\n)\n\n# Configuración del early stopping\nearly_stopping_callback = EarlyStoppingCallback(\n    early_stopping_patience=2,  # Número de épocas sin mejora antes de detener\n    early_stopping_threshold=0.01  # Umbral mínimo de mejora requerido\n)\n\ntrainer_detests = Trainer(\n    model=model,\n    args=training_args_detests,\n    train_dataset=tokenized_train_detests_resampled,\n    eval_dataset=tokenized_valid_data_detests_resampled,\n    compute_metrics=compute_metrics,\n    callbacks=[early_stopping_callback],\n    optimizers=(optimizer, None),  # Aquí se usa el optimizador explícito\n    data_collator=data_collator\n)\n\n# Entrenamiento y evaluación del modelo de detests\ntrainer_detests.train()\ntrainer_detests.evaluate()\n\n# Configuración para el modelo de stereohoax\ntraining_args_stereohoax = TrainingArguments(\n    output_dir='./results_stereohoax',\n    num_train_epochs=6,  # 4 épocas\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    eval_strategy=\"epoch\",\n    logging_dir='./logs_stereohoax',\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    save_strategy='epoch',\n    weight_decay=0.06242226257042495,  # También definido aquí\n    learning_rate=2.103090443160085e-05,\n    logging_steps=10,\n    save_total_limit=3,\n    lr_scheduler_type='linear',\n    warmup_ratio=0.1\n)\n\ntrainer_stereohoax = Trainer(\n    model=model,\n    args=training_args_stereohoax,\n    train_dataset=tokenized_train_stereohoax_resampled,\n    eval_dataset=tokenized_valid_data_stereohoax_resampled,\n    compute_metrics=compute_metrics,\n    callbacks=[early_stopping_callback],\n    optimizers=(optimizer, None),  # Aquí también\n    data_collator=data_collator\n)\n\n# Entrenamiento y evaluación del modelo de stereohoax\ntrainer_stereohoax.train()\ntrainer_stereohoax.evaluate()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 13. Saving Models","metadata":{}},{"cell_type":"code","source":"trainer_detests.save_model(\"./model_detests\")\n\ntrainer_stereohoax.save_model(\"./model_stereohoax\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 14. Testing Models","metadata":{}},{"cell_type":"markdown","source":"## 14.1. Tokenization of Test Subset","metadata":{}},{"cell_type":"code","source":"# Tokenizar los textos de prueba\ntokenized_test_data_detests = test_data_detests.map(\n    lambda x: bert_tokenizer(x['text'], padding=True, truncation=True, max_length=256),\n    batched=True\n)\n\ntokenized_test_data_stereohoax = test_data_stereohoax.map(\n    lambda x: bert_tokenizer(x['text'], padding=True, truncation=True, max_length=256),\n    batched=True\n)\n\n# Convertir los conjuntos de datos tokenizados al formato de PyTorch\ntokenized_test_data_detests = tokenized_test_data_detests.with_format(\n    \"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n)\ntokenized_test_data_stereohoax = tokenized_test_data_stereohoax.with_format(\n    \"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 14.2. Model Testing","metadata":{}},{"cell_type":"code","source":"test_results_detests = trainer_detests.predict(tokenized_test_data_detests)\npredictions_detests = test_results_detests.predictions.argmax(axis=-1)\nlabels_detests = test_results_detests.label_ids\n\nprint(predictions_detests)\nprint(classification_report(labels_detests, predictions_detests))\n\ntest_results_stereohoax = trainer_stereohoax.predict(tokenized_test_data_stereohoax)\npredictions_stereohoax = test_results_stereohoax.predictions.argmax(axis=-1)\nlabels_stereohoax = test_results_stereohoax.label_ids  # Corrige esta línea\n\nassert len(predictions_stereohoax) == len(labels_stereohoax), \"Dimensiones no coinciden.\"\nprint(predictions_stereohoax)\nprint(classification_report(labels_stereohoax, predictions_stereohoax))\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 15. ROC Curves","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, precision_recall_curve\nimport matplotlib.pyplot as plt\nimport torch\n\ndef plot_curves(trainer, eval_dataset, title):\n    # Obtener predicciones y etiquetas reales\n    predictions = trainer.predict(eval_dataset)\n    \n    # Extraer las probabilidades y las etiquetas reales\n    probs = predictions.predictions  # Logits o probabilidades\n    labels = predictions.label_ids\n    \n    # Convertir logits a probabilidades con softmax (si no es directamente una probabilidad)\n    probs = torch.nn.functional.softmax(torch.tensor(probs), dim=-1).numpy()\n    \n    # Para las curvas, necesitamos las probabilidades de la clase positiva\n    positive_probs = probs[:, 1]\n    \n    # Calcular la curva ROC\n    fpr, tpr, _ = roc_curve(labels, positive_probs)\n    roc_auc = auc(fpr, tpr)\n    \n    # Calcular la curva de precisión-recall\n    precision, recall, _ = precision_recall_curve(labels, positive_probs)\n    pr_auc = auc(recall, precision)\n    \n    # Graficar la curva ROC\n    plt.figure(figsize=(12, 5))\n    \n    # Subplot para la curva ROC\n    plt.subplot(1, 2, 1)\n    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Línea diagonal (clasificador aleatorio)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'ROC Curve - {title}')\n    plt.legend(loc=\"lower right\")\n    plt.grid(alpha=0.3)\n    \n    # Subplot para la curva de precisión-recall\n    plt.subplot(1, 2, 2)\n    plt.plot(recall, precision, color='green', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(f'Precision-Recall Curve - {title}')\n    plt.legend(loc=\"lower left\")\n    plt.grid(alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Generar y mostrar las curvas para el modelo detests\nplot_curves(trainer_detests, tokenized_test_data_detests, title=\"detests\")\n\n# Generar y mostrar las curvas para el modelo stereohoax\nplot_curves(trainer_stereohoax, tokenized_test_data_stereohoax, title=\"stereohoax\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ndef plot_confusion_matrix(trainer, eval_dataset, title):\n    # Obtener predicciones y etiquetas reales\n    predictions = trainer.predict(eval_dataset)\n    \n    # Extraer las probabilidades y las etiquetas reales\n    probs = predictions.predictions  # Logits o probabilidades\n    labels = predictions.label_ids\n    \n    # Convertir logits a probabilidades con softmax (si no es directamente una probabilidad)\n    probs = torch.nn.functional.softmax(torch.tensor(probs), dim=-1).numpy()\n    \n    # Obtener la clase predicha (la clase con mayor probabilidad)\n    predicted_classes = probs.argmax(axis=-1)\n    \n    # Calcular la matriz de confusión\n    cm = confusion_matrix(labels, predicted_classes)\n    \n    # Mostrar la matriz de confusión\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])  # Cambiar las etiquetas si no son binarias\n    disp.plot(cmap=plt.cm.Blues)\n    plt.title(f'Confusion Matrix - {title}')\n    plt.show()\n\n# Generar y mostrar la matriz de confusión para el modelo detests\nplot_confusion_matrix(trainer_detests, tokenized_test_data_detests, title=\"detests\")\n\n# Generar y mostrar la matriz de confusión para el modelo stereohoax\nplot_confusion_matrix(trainer_stereohoax, tokenized_test_data_stereohoax, title=\"stereohoax\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 16. Creation, Training and Evaluation of the Ensemble","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\n# Crear un nuevo modelo para el ensamble\nclass EnsembleModel(torch.nn.Module):\n    def __init__(self, model1, model2):\n        super(EnsembleModel, self).__init__()\n        self.model1 = model1\n        self.model2 = model2\n\n    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n        outputs1 = self.model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        outputs2 = self.model2(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        logits = (outputs1.logits + outputs2.logits) / 2\n        return logits\n\n# Dataset para el test\nclass TestDataset(Dataset):\n    def __init__(self, texts, tokenizer, max_length=512):\n        self.texts = texts\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        inputs = self.tokenizer(\n            text,\n            max_length=self.max_length,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\"\n        )\n        return {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n        }\n\n# Configurar el dispositivo\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Cargar modelos entrenados\nmodel1 = BertForSequenceClassification.from_pretrained(\"./model_detests\").to(device)\nmodel2 = BertForSequenceClassification.from_pretrained(\"./model_stereohoax\").to(device)\n\n# Crear el modelo ensamblado\nensemble_model = EnsembleModel(model1, model2).to(device)\nensemble_model.eval()\n\n# Cargar el tokenizador existente\ntokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n\n# Cargar y preprocesar el archivo test.csv\ntest_data = pd.read_csv(\"/kaggle/input/i2c-challenge-dataset/test.csv\")\ntest_data[\"text\"] = test_data[\"text\"].apply(preprocess_text)\ntexts = test_data[\"text\"].tolist()\nids = test_data[\"id\"].tolist()\n\n# Crear DataLoader para el test set\ntest_dataset = TestDataset(texts, tokenizer)\ntest_dataloader = DataLoader(test_dataset, batch_size=16)\n\n# Realizar predicciones\npredictions = []\nwith torch.no_grad():\n    for batch in test_dataloader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        logits = ensemble_model(input_ids, attention_mask)\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        predictions.extend(preds)\n\n# Crear el archivo de resultados\nresults = pd.DataFrame({\"id\": ids, \"stereotype_predicted\": predictions})\nresults.to_csv(\"run_1_berto_sinonimos_08.csv\", index=False)\n\nprint(\"Predicciones guardadas en 'predictions.csv'\")\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 17. Testing the Ensemble with train.csv","metadata":{}},{"cell_type":"code","source":"# Cargar el dataset original\ntrain_data = pd.read_csv(\"/kaggle/input/i2c-challenge-dataset/train.csv\")\n\n# Filtrar datos por las fuentes 'detests' y 'stereohoax'\ndetests = train_data[train_data['source'] == 'detests']\nstereohoax = train_data[train_data['source'] == 'stereohoax']\n\n# Concatenar los dos conjuntos de datos\noriginal_data = pd.concat([detests, stereohoax])\n\n# Aplicar preprocesado a los textos\noriginal_data[\"text\"] = original_data[\"text\"].apply(preprocess_text)\n\n# Extraer textos preprocesados y etiquetas reales\ntexts = original_data[\"text\"].tolist()\nlabels = original_data[\"stereotype\"].tolist()\n\n# Crear DataLoader para el conjunto original utilizando TestDataset\noriginal_dataset = TestDataset(texts, tokenizer)\noriginal_dataloader = DataLoader(original_dataset, batch_size=16)\n\n# Realizar predicciones y calcular el porcentaje de acierto con barra de progreso\npredictions = []\nwith torch.no_grad():\n    for batch in tqdm(original_dataloader, desc=\"Procesando batches\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        logits = ensemble_model(input_ids, attention_mask)\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        predictions.extend(preds)\n\n# Comparar predicciones con etiquetas reales\ncorrect_predictions = sum(p == l for p, l in zip(predictions, labels))\ntotal_samples = len(labels)\naccuracy = correct_predictions / total_samples * 100\n\nf1 = f1_score(labels, predictions, average=\"weighted\")\n\n# Mostrar resultados\nprint(f\"Porcentaje de acierto: {accuracy:.2f}%\")\nprint(f\"F1 Score: {f1:.2f}\")","metadata":{},"outputs":[],"execution_count":null}]}